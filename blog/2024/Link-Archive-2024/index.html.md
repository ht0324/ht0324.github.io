# Link Archive - 2024
_Published: 2024-12-20_
_Tags: AI_
_Categories: Link_
_Original: https://ht0324.github.io/blog/2024/Link-Archive-2024/_

<p>Here’s a collection of links that I enjoyed reading in 2024. It’s not a complete list, as schoolwork often kept me from meticulously tracking everything, but these are the highlights. In 2025, I plan to share these monthly, with more detail and a wider scope.</p>

<hr />

<p><strong><a href="https://geohot.github.io//blog/jekyll/update/2024/01/30/cruise.html">Cruise</a></strong></p>

<ul>
  <li>I’ve always admired George Hotz for his unconventional ideas, and this one is no exception. It’s a movie plot he conceived, and while it may not be as mind-blowing as some of his other work, I enjoyed it.</li>
</ul>

<p><strong><a href="https://qntm.org/transi">Valuable Humans in Transit</a></strong></p>

<ul>
  <li>This story is a great example of “show, don’t tell.” In good science fiction, especially hard science fiction, the context isn’t immediately clear. The story unfolds gradually, and the world-building reveals itself through the narrative. Initially, the narrator’s words might seem confusing, but the situation becomes clear as you continue reading.</li>
</ul>

<p><strong><a href="https://www.bloomberg.com/features/2024-ai-unlock-ancient-world-secrets/">Can AI Unlock the Secrets of the Ancient World?</a></strong></p>

<ul>
  <li>This article details a competition where scientists are attempting to decipher scrolls that were burned and buried during the eruption of Mount Vesuvius. Using advanced CT scans and AI for pattern recognition, they’re making progress in reading these seemingly destroyed texts. I recall hearing about this project a couple of years ago, and seeing its fruition is impressive. It reinforces my optimism about technology.</li>
</ul>

<p><strong><a href="https://waitbutwhy.com/2024/02/vision-pro.html">All My Thoughts After 40 Hours in the Vision Pro - Tim Urban</a></strong></p>

<ul>
  <li>Tim Urban’s review of the Vision Pro resonated with me. While I agree with his overall assessment, I believe the convenience factor needs more consideration. A large display strapped to your face can be cumbersome and inconvenient, which might deter widespread adoption.</li>
</ul>

<p><strong><a href="https://www.wsj.com/tech/ai/sam-altman-openai-protected-by-silicon-valley-friends-f3efcf68">Sam Altman’s Knack for Dodging Bullets - With a Little Help From Bigshot Friends - WSJ</a></strong></p>

<ul>
  <li>I’ve always recognized Sam Altman’s intelligence from his talks and podcasts, but I hadn’t realized the extent of his manipulative tendencies. This article provides a more grounded perspective on the OpenAI drama of late 2023, revealing it as a power struggle where Ilya Sutskever ultimately lost.</li>
</ul>

<p><strong><a href="https://www.newyorker.com/magazine/2023/12/11/the-inside-story-of-microsofts-partnership-with-openai">The Inside Story of Microsoft’s Partnership with OpenAI - The New Yorker</a></strong></p>

<ul>
  <li>This article offers Microsoft’s perspective on the OpenAI upheaval. It describes Microsoft’s frustration and how they leveraged their position to their advantage.</li>
</ul>

<p><strong><a href="https://www.newyorker.com/science/elements/what-are-dreams-for">What Are Dreams For? - The New Yorker</a></strong></p>

<ul>
  <li>Explores the curious phenomenon of twitching during dreams. It turns out our brains aren’t causing the twitches; it’s the other way around. Our bodies twitch, and our brains respond. The hypothesis is that our brains are recalibrating by listening to our bodies during sleep. Fascinating!</li>
</ul>

<p><strong><a href="https://www.newyorker.com/culture/annals-of-inquiry/how-much-of-the-world-is-it-possible-to-model">How Much of the World Is It Possible to Model? - The New Yorker</a></strong></p>

<ul>
  <li>As someone intrigued by the simulation hypothesis, I expected this article to delve into the philosophical implications of simulating the world. Instead, it provided a concise overview of the concept and history of simulation. While it briefly touched on large language models as simulations of thought, I found it somewhat lacking in depth.</li>
</ul>

<p><strong><a href="https://rosslazer.com/posts/fine-tuning/">Fine-tuning GPT3.5-turbo based on 140k slack messages</a></strong></p>

<ul>
  <li>This short blog post details the author’s experience fine-tuning GPT-3.5 with a massive dataset of Slack messages to mimic their writing style. The results, as shown in the image below, demonstrate that fine-tuning can be effective, but it’s not a good idea to use it for everything.</li>
</ul>

<p><strong><a href="https://www.newyorker.com/magazine/2008/06/30/the-itch">The Itch - The New Yorker</a></strong></p>

<ul>
  <li>This article includes a fascinating quote: “If visual sensations were primarily received rather than constructed by the brain, you’d expect that most of the fibres going to the brain’s primary visual cortex would come from the retina. Instead, scientists have found that only twenty per cent do; eighty per cent come downward from regions of the brain governing functions like memory. Richard Gregory, a prominent British neuropsychologist, estimates that visual perception is more than ninety per cent memory and less than ten per cent sensory nerve signals.” This suggests our brains heavily compress visual information.</li>
</ul>

<p><strong><a href="https://www.newyorker.com/humor/daily-shouts/new-years-resolutions-for-an-anteater">New Year’s Resolutions for an Anteater - The New Yorker</a></strong></p>

<ul>
  <li>A funny piece. It makes me want to be an anteater!</li>
</ul>

<p><strong><a href="https://docs.anthropic.com/claude/prompt-library">Prompt Library - Anthropic</a></strong></p>

<ul>
  <li>A useful library of prompts designed for use with Anthropic’s Claude model.</li>
</ul>

<p><strong><a href="https://horace.io/brrr_intro.html">Making Deep Learning Go Brrrr From First Principles</a></strong></p>

<ul>
  <li>This post captures the “bitter lesson” and its implications for LLMs. The memes are also quite entertaining.</li>
</ul>

<p><strong><a href="https://www.palladiummag.com/2024/05/17/my-last-five-years-of-work/">My Last Five Years of Work - Palladium Magazine</a></strong></p>

<ul>
  <li>Written by an Anthropic employee, this article reflects on the changing nature of work in the age of potential superintelligence. It offers a glimpse into the thoughts of AI lab insiders, although I don’t fully agree with the author’s predictions. Still worth reading.</li>
</ul>

<p><strong><a href="https://www.sequoiacap.com/article/ais-600b-question/">AI’s $600B Question</a></strong></p>

<ul>
  <li>This article argues that compute will get cheaper, and GPUs will depreciate faster than expected. I believe there’s truth to this.</li>
</ul>

<p><strong><a href="https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1">FineWeb: decanting the web for the finest text data at scale - a Hugging Face Space by HuggingFaceFW</a></strong></p>

<ul>
  <li>This provides a detailed explanation of how to preprocess vast amounts of web data for LLM pretraining. It emphasizes the importance of careful deduplication and filtering for educational content using LLM labeling.</li>
</ul>

<p><strong><a href="https://www.newyorker.com/magazine/2018/12/10/the-friendship-that-made-google-huge">The Friendship That Made Google Huge</a></strong></p>

<ul>
  <li>Another New Yorker piece, this one about Jeff Dean and his colleagues. It shows Dean’s brilliance and how Google’s ability to scale was its true strength. I wonder if that still holds true today. The close intellectual synchronization between Jeff Dean and Sanjay Ghemawat, developed through years of collaboration, is particularly intriguing.</li>
</ul>

<p><strong><a href="https://nicholas.carlini.com/writing/2024/how-i-use-ai.html#background">How I Use AI - Nicholas Carlini</a></strong></p>

<ul>
  <li>A piece by a DeepMind researcher on how he uses AI. His approach aligns with my own and what I advocate for.</li>
</ul>
