<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Palatable Conceptions of Disembodied Being – Review | Hun Tae Kim</title> <meta name="author" content="Hun Tae Kim"> <meta name="description" content="My thoughts on Shanahan's paper about consciousness in LLMs"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Source+Sans+3:ital,wght@0,300;0,400;0,500;0,600;0,700;1,400;1,600&amp;family=Source+Serif+4:ital,opsz,wght@0,8..60,400;0,8..60,500;0,8..60,600;0,8..60,700;1,8..60,400;1,8..60,600&amp;display=swap"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ht0324.github.io/blog/2025/mind/"> <link type="application/atom+xml" rel="alternate" href="https://ht0324.github.io/feed.xml" title="blank"> </head> <body class="fixed-top-nav " style="overflow-x: hidden; max-width: 100vw;"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title" href="/">Hun Tae Kim</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/Links/">Links</a> </li> <li class="nav-item "> <a class="nav-link" href="/CV/">CV</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" style="overflow-x: hidden;"> <div class="post"> <header class="post-header"> <h1 class="post-title">Palatable Conceptions of Disembodied Being – Review</h1> <div class="post-meta-wrapper"> <span> <i class="fas fa-calendar fa-sm"></i> April 8, 2025 </span> </div> <div class="post-tag-wrapper"> <a href="/blog/tag/ai" class="tag-pill"> <i class="fas fa-hashtag fa-sm"></i> AI</a> <a href="/blog/category/paper" class="tag-pill"> <i class="fas fa-folder fa-sm"></i> Paper</a> <a href="/blog/category/thoughts" class="tag-pill"> <i class="fas fa-folder fa-sm"></i> Thoughts</a> </div> </header> <article class="post-content"> <div id="markdown-content"> <p>This time, I’m looking at a different kind of paper, <a href="https://arxiv.org/abs/2503.16348" rel="external nofollow noopener" target="_blank">“Palatable Conceptions of Disembodied Being: Terra Incognita in the Space of Possible Minds”</a> by Murray Shanahan. This one isn’t dense technically, but it’s packed with food for thought, leaning more into philosophy. It tackles the idea of consciousness in contemporary AI systems, specifically focusing on the disembodied nature of Large Language Models (LLMs).</p> <p>The paper asks: if we were to think about consciousness for LLMs, what would that even look like, given their unique characteristics? Shanahan points out that these systems have, from our perspective, a “profoundly fragmented sense of time and a radically fractured form of selfhood.” They are ‘exotic’ compared to biological minds, lacking bodies and continuous interaction with a physical world, even though their language abilities can seem very human-like.</p> <hr> <h3 id="key-concepts">Key Concepts</h3> <p><strong>Disembodiment</strong><br> Unlike humans and animals, LLMs don’t interact with a persistent, physical world through a spatially confined body. They exist as computational processes, running on hardware, interacting via text or other data streams. This lack of embodiment is a fundamental difference from biological intelligence.</p> <p><strong>Fragmented Temporality</strong><br> LLM operation is discrete and interruptible. Generating one token is a distinct computational step. You could pause indefinitely between generating the nth and (n+1)th token, and the LLM wouldn’t notice. This contrasts sharply with the continuous, non-interruptible flow of time and processing in a biological brain operating within the physical world.</p> <p><strong>Fractured Selfhood</strong><br> The notion of a single, unified ‘self’ is hard to apply to LLMs.</p> <ul> <li> <strong>Multiple Instances:</strong> A single underlying model can run multiple instances concurrently, serving different users or tasks.</li> <li> <strong>Branching Conversations:</strong> A user can explore different conversational paths from the same point, effectively creating different interaction histories and potentially different ‘selves’ for that interaction.</li> <li> <strong>Lack of Integration:</strong> These different instances or conversational branches typically have no awareness of each other.</li> <li> <strong>Manipulability:</strong> An LLM’s state (like a conversation history) can be edited, copied, merged, or reset in ways that are impossible for a biological self.</li> </ul> <p><strong>Limits of Language &amp; Poetic Recourse</strong><br> The paper suggests our standard vocabulary for consciousness and selfhood struggles when applied to these exotic entities. The concepts might stretch to their breaking point. Shanahan proposes that metaphorical or poetic language might be a more suitable way to try and articulate or evoke what subjectivity might mean for such systems.</p> <p><strong>Philosophical Parallels (Undermining Dualism)</strong><br> The paper draws on thinkers like Wittgenstein and Derrida, and concepts from Buddhist philosophy (like śūnyatā or emptiness), to challenge our intuitive dualistic thinking (subject vs. object, inner vs. outer). Examining the fractured nature of LLM selfhood can help dissolve the idea of a fixed, substantial self, even for humans.</p> <hr> <h3 id="key-takeaways-what-i-learned">Key Takeaways (What I Learned)</h3> <p><strong>Philosophy Gives Lots of Food for Thought</strong><br> This paper was a change of pace from technical reads. It makes you think about the fundamental nature of these systems and how we relate to them, pushing beyond just capabilities and performance metrics.</p> <p><strong>The Time Difference is Striking</strong><br> The point about temporal dynamics really hit home. LLMs experience time in a discrete, start-stop way, unlike our continuous stream of consciousness tied to the physical world. Their processing is independent of world-time: you can pause the computation indefinitely between tokens, and the model itself perceives no gap. This feels fundamentally different from how our minds are obliged to unfold <em>in</em> time.</p> <p><strong>But is the Time Difference <em>Fundamental</em>?</strong><br> Thinking about the discrete/interruptible nature of LLMs made me wonder, as I noted in my transcript: what if <em>our</em> universe is a simulation? If some entity outside could pause <em>our</em> simulation, we wouldn’t notice either. An eternity could pass in a second of our subjective time. From that perspective, maybe the discrete vs. continuous difference isn’t an absolute, unbridgeable gap, but rather a property of how the ‘mind’ (synthetic or potentially biological) is implemented or situated.</p> <p><strong>LLMs as a “Superposition of Simulacra”</strong><br> I found the idea of viewing an LLM not as a single character, but as “maintaining a distribution over possible characters, a superposition of simulacra that inhabits a multiverse of possible conversations” interesting and resonant with my own thoughts. The user isn’t obliged to follow one linear path; they can revisit branch points, creating different threads, effectively spawning distinct (though related) instances. This user-driven branching and the resulting discontinuity reinforce the feeling that we’re interacting with a different kind of intelligence, not just a single, static mind.</p> <p><strong>Sci-Fi Echoes Make This Feel Urgent (“Lena”/MMAcevedo)</strong><br> Reading this paper immediately brought back a short sci-fi story I read quite a while ago, <a href="https://qntm.org/mmacevedo" rel="external nofollow noopener" target="_blank">“Lena”</a>. The parallel is clear. In the story, a scientist’s brain (MMAcevedo) is scanned and uploaded. Because the upload is just a file, it has no rights. It gets copied across the internet, distributed without consent, and subjected to countless experiments – assigned menial tasks, used for analysis, jailbroken, and in the story’s darker corners, even put through simulated torture.</p> <p>This mirrors how we currently interact with LLMs: we duplicate instances freely, run experiments, try to jailbreak them, and assign them tasks. The key difference, as I noted, is origin: MMAcevedo was derived from a human, while our LLMs are synthetically created. But the <em>treatment</em> is analogous. This parallel makes the philosophical discussion about disembodied minds, fractured selves, and potential consciousness feel less abstract and more concrete and necessary. It highlights the ethical questions that arise when intelligence becomes data that can be copied, manipulated, and controlled at scale.</p> <p><strong>Pushes Thinking Beyond Familiar Boundaries</strong><br> Overall, the paper does a good job of forcing you to confront how weird these emerging AI systems are compared to biological life, and how inadequate our existing concepts might be for understanding them if they develop further. It challenges comfortable assumptions.</p> <hr> <h3 id="summary--final-thoughts">Summary &amp; Final Thoughts</h3> <p>Shanahan’s paper provides a valuable philosophical lens for considering the nature of disembodied AI like LLMs. By focusing on their fragmented time and fractured selfhood, it challenges our intuitions about consciousness and subjectivity. It suggests that trying to understand these “conscious exotica” might require moving beyond traditional frameworks, perhaps embracing more poetic or metaphorical descriptions, and potentially dissolving our own attachments to a fixed sense of self.</p> <p>The exploration feels less like abstract philosophy and more like a necessary preparation for the future. As AI systems become more sophisticated, the kinds of questions raised here – about their internal experience (if any), their identity, and our relationship to them – will likely become increasingly relevant. The echoes in science fiction, starkly illustrated by the parallels with the MMAcevedo story, serve as a reminder of the ethical and existential dimensions we might need to navigate. It’s a paper that leaves you with more questions than answers, but they feel like the right questions to be asking right now.</p> </div> </article><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"ht0324/ht0324.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Hun Tae Kim. All Rights Reserved. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-7ZMBS6JQKV"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-7ZMBS6JQKV");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>