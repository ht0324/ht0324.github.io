# System 1, System 2
_Published: 2025-04-12_
_Tags: AI_
_Categories: Thoughts_
_Original: https://ht0324.github.io/blog/2025/sys1/_

<p>Our thinking operates on two levels. System 1 acts quickly, intuitively, efficient, yet prone to error. System 2 engages slowly, deliberately, requiring effort for greater accuracy. Daniel Kahneman detailed this duality in <em>Thinking, Fast and Slow</em>, describing these complementary modes of mind.</p>

<p><a href="https://www.lesswrong.com/posts/BoA3agdkAzL6HQtQP/clarifying-and-predicting-agi">T-AGI</a>, Artificial General Intelligence measured against time. A system reaches T-AGI if it surpasses human performance on a task within a set duration T. Perhaps today’s large language models already approach a sub-hour T-AGI for certain cognitive work: rapid research, coding assistance, factual recall.</p>

<p>Do these models already outperform our own System 1 thinking? For instant recall, like obscure facts or historical details, they often respond with superior speed and accuracy. While techniques like Chain-of-Thought aim for deeper reasoning, their fundamental strength seems rooted in this rapid, pattern-matching mode. System 1 scaled.</p>

<p>Perhaps we should embrace this strength. Let the model be the powerful System 1 engine. Then, pair it with a distinct, perhaps more structured, System 2. Retrieval Augmented Generation (RAG) hints at this, combining parametric models (the LLM’s weights) with non-parametric knowledge (retrieved data). An analogy for instinct coupled with explicit information.</p>

<p>The true potential may lie in strengthening that second system, grounding it with deep context. Consider an AI accessing <em>your</em> personal knowledge – your memories, experiences, learned values, your unique nuance. What is a human stripped of memory, of personal history? An echo without a source, adrift. Our past is the lens through which we understand the present.</p>

<p>An AI infused with such personal context could become a true cognitive partner. It could navigate the complexities of the world alongside us, offering insights tuned not just to general data, but to our individual lives. Perhaps, as Yuval Noah Harari posited, such systems could eventually learn to make better decisions on our behalf. The result: intelligence deeply personalized, genuinely valuable.</p>
