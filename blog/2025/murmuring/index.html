<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>The Murmuring Woman | Hun Tae Kim</title> <meta name="author" content="Hun Tae Kim"> <meta name="description" content="A Parable for LLM Thinking"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Source+Sans+3:ital,wght@0,300;0,400;0,500;0,600;0,700;1,400;1,600&amp;family=Source+Serif+4:ital,opsz,wght@0,8..60,400;0,8..60,500;0,8..60,600;0,8..60,700;1,8..60,400;1,8..60,600&amp;display=swap"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ht0324.github.io/blog/2025/murmuring/"> <link type="application/atom+xml" rel="alternate" href="https://ht0324.github.io/feed.xml" title="blank"> </head> <body class="fixed-top-nav " style="overflow-x: hidden; max-width: 100vw;"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title" href="/">Hun Tae Kim</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/Links/">Links</a> </li> <li class="nav-item "> <a class="nav-link" href="/CV/">CV</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" style="overflow-x: hidden;"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Murmuring Woman</h1> <div class="post-meta-wrapper"> <span> <i class="fas fa-calendar fa-sm"></i> May 10, 2025 </span> </div> <div class="post-tag-wrapper"> <a href="/blog/tag/ai" class="tag-pill"> <i class="fas fa-hashtag fa-sm"></i> AI</a> <a href="/blog/category/thoughts" class="tag-pill"> <i class="fas fa-folder fa-sm"></i> Thoughts</a> </div> </header> <article class="post-content"> <div id="markdown-content"> <p>I had a peculiar experience today that I wanted to share. I was at a cafe with my girlfriend, planning our vacation. Nearby, there was a woman, maybe in her mid-40s, wearing a face mask. She was constantly murmuring to herself – not loudly, I couldn’t make out the words, but it was non-stop. She looked really agitated, getting up, sitting down slightly differently, pacing out of the room and then returning to the same seat. This went on and on. As we wrapped up our trip planning, I looked up, and she was just gone. That quick.</p> <p>Our vacation plans came together well, but the image of that woman kind of lingered in my head. When I saw her, it really reminded me of large language models. I had to admit that my brain is so stuffed with AI these days – for better or worse.</p> <p>Hear me out.</p> <h3 id="from-self-talk-to-chain-of-thought">From Self-Talk to Chain-of-Thought</h3> <p>The woman’s constant self-talking, that murmuring, felt exactly like what chain-of-thought reasoning models are currently doing. It’s a very simple, almost too easy analogy, but if you start to put weight on it, it feels really, really profound. I don’t know why this happens, but I find that anthropomorphizing large language models sometimes helps me see what capabilities they might need or what data we should give them to make them more capable. These kinds of analogies make it easier for me to see things.</p> <p>There’s a sort of stack here, a progression:</p> <ol> <li> <strong>Traditional LLMs:</strong> These models don’t really “think” in a step-by-step way. They just generate, often verbatim, without much pause – a kind of knee-jerk reaction. This is like System 1 thinking.</li> <li> <strong>Reasoning Models (Chain-of-Thought):</strong> When these came along, they blew the older models out of the water. This introduced a new scaling paradigm: test-time compute. Introspection, or thinking step-by-step, is much better than a knee-jerk response for many tasks. This is System 2, and it’s really good for improving capabilities. <a href="https://www.youtube.com/watch?v=eaAonE58sLU" rel="external nofollow noopener" target="_blank">Noam Brown’s work</a> really pioneered this area.</li> </ol> <h3 id="the-limits-of-introspection-and-the-need-for-tools">The Limits of Introspection and the Need for Tools</h3> <p>Now, what current models are doing is moving towards becoming agents. And here’s where the analogy with the woman (and I want to be clear, I don’t know her or what she was going through, but she really looked like she was having a tough time – this is just an observation for the sake of analogy) becomes even more interesting.</p> <p>Constant introspection, just talking to oneself, only gets you so far. And that’s exactly the limit I see with first-generation reasoning models, like some of the DeepSeek models or OpenAI’s o1. They can think, they can “talk to themselves” on and on, but they can’t verify their own thoughts quite reliably.</p> <p>Compare this to how people generally operate. When “normal” people think, they can self-verify using external tools or interactions. They might talk something through with someone else for verification, or rely on external aids like their iPhone, a book, or a quick search. This analogy is simple. And that’s what models like Anthropic’s Claude 3.7 Sonnet and OpenAI’s o3 are doing now. They are good at interacting with the real world via an external pipeline, a bridge we call “tools.”</p> <h3 id="the-fine-line-of-anthropomorphism">The Fine Line of Anthropomorphism</h3> <p>When you anthropomorphize a large language model this way, the need for tools and external interaction becomes obvious. But there’s a key caveat: the internal modeling of an LLM is very different from human cognition. I’m anthropomorphizing for the sake of seeing what LLMs might <em>benefit from</em>, what might make them more capable. It’s a fine line to walk.</p> <h3 id="arent-we-all-just-next-word-predictors">Aren’t We All Just Next-Word Predictors?</h3> <p>As this kind of anthropomorphization continues, and it’s easy to do because language models can seem persuasive and lifelike, it reminded me of something <a href="https://youtube.com/watch?v=XgCHZ1G93iA&amp;t=438" rel="external nofollow noopener" target="_blank">Scott Aaronson said</a> a year ago. When LLMs first emerged and there were naysayers arguing “it’s just next-word prediction, just statistical modeling,” he’d retort (paraphrasing) “But what about you? Aren’t <em>you</em> just a next-word predictor? What about your mom?”</p> <p>It really kind of cracked me up at the time. If I’d said that to some of my close friends who looked down upon LLMs, they would have fumed, they’d be outraged! But when ChatGPT came out, I intuitively, wholeheartedly agreed with Aaronson’s point. My mind hasn’t changed on that.</p> <p>I think as models get more capable, Aaronson’s quip: “aren’t we just the next-word predictor?”, will become true in a functional sense. Recently, LLMs passed the turing test, but society has moved on like nothing happened. Sooner or later, for every verifiable task, model capabilities will likely exceed human capabilities. And still, when that happens, they will be, at their core, next-word predictors. Superhuman next-word predictors, better than us at any given task.</p> <p>Then what would we become?</p> </div> </article><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"ht0324/ht0324.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Hun Tae Kim. All Rights Reserved. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-7ZMBS6JQKV"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-7ZMBS6JQKV");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>