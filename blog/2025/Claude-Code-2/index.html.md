# Claude Code - Three Days In
_Published: 2025-03-07_
_Tags: AI_
_Categories: Blog_
_Original: https://ht0324.github.io/blog/2025/Claude-Code-2/_

<p>It’s been three days since I started using <a href="https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview">Claude Code</a>. The initial excitement was so strong that I immediately wrote a <a href="/blog/2025/Claude-Code/">blog post</a> about it. But after a couple more days, having spent more time exploring its capabilities, I’ve found myself with even more thoughts, so here’s a quick follow-up.</p>

<hr />

<h3 id="time-saving-understated-yet-significant">Time-Saving: Understated Yet Significant</h3>

<p>I know I’ve already emphasized how much time Claude Code saves. Over the past couple of days, I’ve been completely revamping my personal website from the ground up. Let me preface this by saying: I’m not really a web guy. Before Claude Code, my blog was just a clone of the <a href="https://alshedivat.github.io/al-folio/">Al Folio</a> theme. Whenever I wanted to tweak something, it felt daunting. Each tiny modification usually ended in frustration or compromise because the effort required to change something small just wasn’t worth it.</p>

<p>Now, if I want to adjust the tag styling or add new functionality, I just instruct Claude Code to do it. It handles the rest. The difference in my blog over just these past couple of days is significant. I’ve implemented numerous nooks and crannies, subtle features, and design tweaks that previously felt impossible.</p>

<p>Of course, Claude isn’t perfect, but the amount of time it saves is substantial. Yesterday I wasn’t satisfied with how the tag feature functioned, so I decided to change it up. Claude handled the entire process for about $1 in API costs. A dollar. Less than a cup of coffee. Without it, the same change would have probably taken me hours of tinkering and frustration.</p>

<p>At first, Claude felt like a pair-programming partner, but even after just three days, that feeling is fading. Instead, it’s become something more like a virtual assistant, an assistant that can actually do things, not just talk about them.</p>

<hr />

<h3 id="chatbots-vs-agents-what-is-vs-do-it">Chatbots vs. Agents: “What Is” vs. “Do It”</h3>

<p>Using traditional chatbots like ChatGPT always felt like carefully constructing queries, specifying every little detail of my intent. Most of my interactions with ChatGPT, and likely yours too, are fundamentally knowledge retrieval: asking “What is this?” or “Tell me about that.” ChatGPT essentially compresses vast internet knowledge and provides succinct, precise answers. It’s exceptional at answering questions and explaining concepts, but it’s mostly passive, focused on understanding and summarizing existing knowledge.</p>

<p>But Claude Code changed things for me. With a truly agentic model like Claude, I don’t have to painstakingly spell out exactly how I want something done. Instead, I just specify <em>what</em> I want done, and Claude figures out the <em>how</em>. It summarizes information and also actively plans, makes decisions, and implements changes autonomously. This shift from explicitly defined instructions (“what is”) to implicit, actionable intent (“do it”) feels profound, a step change in capability that transforms the user experience.</p>

<p>Of course, because Claude isn’t perfect yet, the collaboration still exists in the form of verifying the results. But as I’ve <a href="https://medium.com/@FdForThought/framing-rlhf-as-generation-vs-verification-4d9e95b88534">said before</a> <a href="https://medium.com/@FdForThought/generation-vs-verification-epiphany-after-o1-713c6f411206">many times</a>: verification is easier than generation, and right now, I’m comfortably on the verification side. I check Claude’s implementation by deploying my blog and testing the functionality. This still requires my input, but the mental load is lighter.</p>

<hr />

<h3 id="from-collaboration-to-automation">From Collaboration to Automation</h3>

<p>While it still feels somewhat collaborative now, I’m realizing that my role is already shrinking from active collaborator to passive verifier. It’s an assistant relationship, not really a partnership anymore. Verification feels simpler and simpler, and I can foresee even verification becoming automated soon. At that point, human involvement becomes negligible.</p>

<p>Previously, I believed in the paradigm that self-feedback loops (generation versus verification) would incrementally increase intelligence. But intelligence and agency are fundamentally different. Learning how to be smart/knowledgable and learning how to act are not the same, and the latter is far more powerful. I’m now convinced that agentic capability will lead to implications far bigger and faster than I initially anticipated.</p>

<p>If (or more realistically, <em>when</em>) verification itself is automated, we won’t be collaborating with AI, we’ll be observing it collaborating with itself. That’s when things will get interesting (and potentially unsettling).</p>

<hr />

<h3 id="toward-agentic-intelligence">Toward Agentic Intelligence?</h3>

<p>OpenAI previously described levels of AI intelligence: Level 2 (reasoners), Level 3 (agents), and Level 4 (collaborators or organizations). Claude Code sits loosely at Level 3, and my recent experiences hint strongly that Level 4: agents autonomously collaborating with each other, is closer than we might think.</p>

<p>As these agentic models improve and increasingly handle their own verification, we’ll approach a point where human oversight becomes unnecessary. This isn’t speculation anymore; using Claude Code has convinced me that the shift toward fully autonomous agentic systems is possible and imminent.</p>

<p>The impact of that shift will be significant. As impressive as Claude Code is today, it’s the worst this technology will ever be. And that’s both thrilling and deeply concerning.</p>
