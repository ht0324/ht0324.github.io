<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Link Archive - 2025 - January | Hun Tae Kim</title> <meta name="author" content="Hun Tae Kim"> <meta name="description" content="A collection of articles and videos that I read in January 2025."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ht0324.github.io/blog/2025/Link-Archive-Jan-2025/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Hun Tae </span>Kim</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/Links/">Links</a> </li> <li class="nav-item "> <a class="nav-link" href="/CV/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Link Archive - 2025 - January</h1> <p class="post-meta">January 31, 2025</p> <p class="post-tags"> <a href="/blog/2025"> <i class="fas fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ai"> <i class="fas fa-hashtag fa-sm"></i> AI</a>     ·   <a href="/blog/category/link"> <i class="fas fa-tag fa-sm"></i> link</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>A curated list of links I found insightful in January 2025. This is the first of what I hope will be a monthly series.</p> <hr> <p><strong><a href="https://www.aisnakeoil.com/p/is-ai-progress-slowing-down" rel="external nofollow noopener" target="_blank">Is AI Progress Slowing Down?</a></strong></p> <ul> <li>This post offers a comprehensive take on where AI stands as of December 2024. The author takes a rational and conservative approach, using first principles. For example, while not buying into the hype from Sam Altman and other leading AI labs, they <em>also</em> believe that model scaling is far from over and that there’s no real evidence to suggest otherwise. It’s interesting that the blog points out that Altman and Sutskever have an incentive to shape the narrative, and their statements might not be the whole truth. The post touches on inference scaling too. Overall, a well-balanced piece.</li> </ul> <p><strong><a href="https://willwhitney.com/computing-inside-ai.html" rel="external nofollow noopener" target="_blank">Computing Inside AI</a></strong></p> <ul> <li>I think Human-Computer Interaction (HCI) is super important. A computer is fundamentally a tool, and it’s most useful when we streamline the interaction with humans, eliminating bottlenecks and inconveniences. Human-AI interaction isn’t really an established field yet, but I believe it <em>will</em> be. The author argues that instead of interacting with current LLMs as if they were people, we should treat them as tools. They suggest an LLM could dynamically generate an interface, similar to a computer. What would that even <em>look</em> like? It’s a really interesting idea because, as the author points out, conversing with AI can be slow and involves this isolated back-and-forth. Human-computer interaction isn’t like that. What if we fundamentally changed how we interact with AI? This is a very thoughtful post.</li> </ul> <p><strong><a href="https://www.engraved.blog/building-a-virtual-machine-inside/" rel="external nofollow noopener" target="_blank">Building a Virtual Machine Inside ChatGPT</a></strong></p> <ul> <li>I first encountered this blog post at the end of 2022, around the advent of ChatGPT, and I recently rediscovered it. The author attempted to simulate a Unix terminal environment using ChatGPT, and, surprisingly, they <em>succeeded</em>. This might not seem remarkable now, but it completely blew my mind when I first started using ChatGPT. The author is really clever, and they take it a step further by going “all meta,” which I won’t spoil. This clearly demonstrated that the LLM could simulate a system—in this case, a Unix system. It gave me this sense that this LLM was something truly special and that it would fundamentally change everything. I still believe that, and I owe that kind of inspiration and shock to this blog post.</li> </ul> <p><strong><a href="https://youtube.com/watch?v=UakqL6Pj9xo" rel="external nofollow noopener" target="_blank">Dwarkesh Patel interviews François Chollet</a></strong></p> <ul> <li>I initially knew François Chollet due to his activity on Twitter as an AI skeptic (or, at least, <em>somewhat</em> of an AI skeptic) and his work on ARC prizes. So, it was exciting to see him interviewed by Dwarkesh Patel. I really enjoyed it because Dwarkesh grilled François on his views on LLMs. I think Dwarkesh’s approach was a bit unfair because, while François made some valid points, Dwarkesh seemed intent on pushing him to say what <em>he</em> wanted, but he ultimately failed to do so. While listening, I felt torn between them. I agree with Dwarkesh’s overall viewpoint but align with François’s specifics regarding intelligence and the core of reasoning. It was a conflicting yet invigorating discussion, and I think I should re-watch it to savor it more.</li> </ul> <p><strong><a href="https://youtube.com/watch?v=Bo8MY4JpiXE" rel="external nofollow noopener" target="_blank">Lex Fridman interviews François Chollet (2019)</a></strong></p> <ul> <li>After the Dwarkesh podcast, I turned to Lex Fridman’s podcast to hear more from François Chollet. And, in classic Lex Fridman fashion, he delivered. This first one is an earlier interview from 2019, when François was much younger. In current public settings, François appears more glum and calm, but in this interview, I could see a sparkle and a smile in his eyes and on his face, which was refreshing. This podcast delves into the advent of Keras and TensorFlow, which I really enjoyed.</li> </ul> <p><strong><a href="https://youtube.com/watch?v=PUAdj3w3wO4" rel="external nofollow noopener" target="_blank">Lex Fridman interviews François Chollet (Later)</a></strong></p> <ul> <li>In this podcast, both François and Lex are a bit older. I watched this because I was simultaneously reading François’s paper on the measure of intelligence. He’s soft-spoken but offers insightful perspectives on intelligence. While I don’t agree with everything he says—I believe that LLMs and other AI systems are capable of more generalization than François suggests—I think his views as an AI skeptic aren’t unfounded. His logic is sound, but I believe he underestimates the intuitive power of these machine learning systems.</li> </ul> <p><strong><a href="https://distill.pub/2017/feature-visualization/" rel="external nofollow noopener" target="_blank">Feature Visualization</a></strong></p> <ul> <li>This is an excellent method for visualizing and interpreting models. The paper interprets, reverse-engineers, and reconstructs what features each neuron or layer is attending to in an image. The basic idea is that, through iteration, we generate an image that a particular neuron fires most strongly for. This yields fascinating images of what the neuron has learned, and I find it very compelling.</li> </ul> <p><strong><a href="https://stratechery.com/2025/deepseek-faq/" rel="external nofollow noopener" target="_blank">DeepSeek FAQ</a></strong></p> <ul> <li>This week was all about the buzz surrounding DeepSeek’s release of a model called R1, and Stratechery did it again. Ben Thompson distilled what was important and the broader implications. Ultimately, the biggest winners are the customers and the general public. I think the overall point is that open-sourcing is both morally and practically right, since AI models are becoming commoditized, and costs are racing to the bottom.</li> </ul> <p><strong><a href="https://www.chinatalk.media/p/deepseek-ceo-interview-with-chinas" rel="external nofollow noopener" target="_blank">DeepSeek CEO Interview (ChinaTalk)</a></strong></p> <ul> <li>This is an interview with the DeepSeek CEO, and based on the interview, he is very ambitious and really focused on innovation, which I admire. Previously, China was primarily focused on keeping up with the US, but he feels they need a culture of innovation—not just following, but innovating themselves and becoming trendsetters. It will be a really interesting dynamic, and I’m glad that he is bullish on open-sourcing and that his company remains committed to it.</li> </ul> <p><strong><a href="https://stratechery.com/2025/ais-uneven-arrival/" rel="external nofollow noopener" target="_blank">AI’s Uneven Arrival</a></strong></p> <ul> <li>This is a very interesting take, drawing an analogy between Facebook’s unconventional approach to advertising and the previous advertising agency model. Facebook directly connected consumers and advertisers via algorithms. Meanwhile, traditional advertising companies acted as middlemen between ad sellers and big brands. The author connects this to the OpenAI reason model and basically says that those agents will not replace individuals in traditional companies that use people. Instead, AI-driven organizations will likely start without them from the outset.</li> </ul> <p><strong><a href="https://darioamodei.com/on-deepseek-and-export-controls?s=09" rel="external nofollow noopener" target="_blank">Dario Amodei on DeepSeek and Export Controls</a></strong></p> <ul> <li>It’s pretty interesting to see Amodei’s reaction to this, and I think he’s right. If you’re on the American side, the most logical thing to do is to clamp down on AI exports—specifically, chip exports. But the thing is, those chip exports… the Biden administration didn’t constrain the chips on the bandwidth side, so that’s why DeepSeek had a workaround utilizing maximum bandwidth. But if they clamp down on both bandwidth and compute, I’m not sure that would be the fundamental solution to this arms race.</li> </ul> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Hun Tae Kim. All Rights Reserved. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-7ZMBS6JQKV"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-7ZMBS6JQKV");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>