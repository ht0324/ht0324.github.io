<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Agency Over Retrieval? | Hun Tae Kim</title> <meta name="author" content="Hun Tae Kim"> <meta name="description" content="Thinking about why o3/o4 mini are prompted to search the web by default."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Source+Sans+3:ital,wght@0,300;0,400;0,500;0,600;0,700;1,400;1,600&amp;family=Source+Serif+4:ital,opsz,wght@0,8..60,400;0,8..60,500;0,8..60,600;0,8..60,700;1,8..60,400;1,8..60,600&amp;display=swap"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ht0324.github.io/blog/2025/o3-o4mini2/"> </head> <body class="fixed-top-nav " style="overflow-x: hidden; max-width: 100vw;"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title" href="/">Hun Tae Kim</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/Links/">Links</a> </li> <li class="nav-item "> <a class="nav-link" href="/CV/">CV</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" style="overflow-x: hidden;"> <div class="post"> <header class="post-header"> <h1 class="post-title">Agency Over Retrieval?</h1> <div class="post-meta-wrapper"> <span> <i class="fas fa-calendar fa-sm"></i> April 18, 2025 </span> </div> <div class="post-tag-wrapper"> <a href="/blog/tag/ai" class="tag-pill"> <i class="fas fa-hashtag fa-sm"></i> AI</a> <a href="/blog/category/blog" class="tag-pill"> <i class="fas fa-folder fa-sm"></i> Blog</a> </div> </header> <article class="post-content"> <div id="markdown-content"> <p>I’ve been thinking more about OpenAI’s o3 and o4 mini models since my <a href="/blog/2025/o3-o4mini-product-path/">last post</a>, and using them led to some additional insights. Specifically, I looked into the <a href="https://x.com/elder_plinius/status/1912567149991776417" rel="external nofollow noopener" target="_blank">system prompt for o3/o4 mini</a> and noticed something interesting: it strongly encourages the model to surf the web whenever a query is even slightly vague or uncertain. Essentially, web search is almost the default behavior.</p> <p>Initially, I was puzzled by this choice. Why prompt a <em>reasoning and agentic</em> model to search the web so readily? These aren’t primarily web search models like Perplexity AI. Why not rely more on their internal knowledge and reasoning first?</p> <p>But as I thought deeper about it, everything kind of clicked.</p> <h3 id="beyond-simple-hallucination-mitigation">Beyond Simple Hallucination Mitigation</h3> <p>Of course, one part of the answer relates to model hallucination. Getting large language models to be consistently reliable and avoid making things up is still a really hard problem. While improvements in data and algorithms have reduced blatant hallucination, ensuring reliability over 99% of the time requires robust grounding. Accessing relevant, up-to-date information is obviously important for that.</p> <p>However, I don’t think that’s the full story here. I think OpenAI is doing something more fundamental by leveraging the <em>agentic</em> capabilities of these models.</p> <h3 id="letting-the-model-choose-its-context">Letting the Model Choose Its Context</h3> <p>Think about traditional approaches like Retrieval-Augmented Generation (RAG). In those systems, a separate retrieval mechanism analyzes the user’s query, finds potentially relevant source documents, and then stuffs that information into the language model’s context window. The retrieval system decides what the main LLM sees.</p> <p>What OpenAI seems to be doing with o3/o4 mini is different. They are offloading the task of finding relevant information <em>to the main model itself</em>. Instead of an external system <em>pushing</em> context, the agentic model is encouraged to <em>pull</em> the context it decides it needs by actively searching the web.</p> <p>Let me break it down with an analogy. Imagine you need to solve a complex problem.</p> <ul> <li> <strong>Option A (RAG-like):</strong> Someone else (a separate system) looks at your problem, finds some books or articles they think are relevant, and hands them to you. You then try to solve the problem using only those materials.</li> <li> <strong>Option B (o3/o4 mini-like):</strong> You look at the problem, and <em>you</em> decide to proactively search your bookshelf, scour the internet, gather information, and based on what you find, iteratively search for more information until <em>you</em> feel you have what you need.</li> </ul> <p>Option B gives you autonomy. You actively choose what information you consume. This feels like a much more effective way to tackle complex or nuanced problems, right?</p> <p>The key difference is agency. The RAG system (Option A) isn’t necessarily as smart or capable as the main LLM it’s feeding context to. Why let a potentially less sophisticated system pre-filter the information? Why not let the powerful base model decide what information is most relevant or needed for its own reasoning process?</p> <p>This principle of giving the model agency to select its own relevant context seems to be more general than just text retrieval via web search. It applies across modalities. Look at OpenAI’s recent post on <a href="https://openai.com/index/thinking-with-images/" rel="external nofollow noopener" target="_blank">“Thinking with Images”</a>. They demonstrate how o3/o4 mini can use tools to manipulate images <em>during</em> their chain of thought. For instance, if text in an image is upside down or hard to read, the model can use tools to zoom in or rotate that specific part of the image to better understand it. If an image is complex, it can zoom into the most relevant section. This is effectively visual information retrieval, driven by the model’s <em>active ability</em> to choose which visual information to focus on using tools, mirroring how it uses web search to retrieve textual information.</p> <p>Traditional RAG can sometimes feel like it just dumps context verbatim into the window, regardless of whether the model actually deems it insightful or sufficient. Giving the model the agency to search – whether the web for text or pixels within an image – means it can dynamically gather precisely what it needs, when it needs it. It’s a recursive, almost meta-cognitive approach – the model decides how to inform itself.</p> <h3 id="consolidation-and-the-bitter-lesson-again">Consolidation and the Bitter Lesson Again?</h3> <p>This feels like another step in the consolidation trend we’ve seen in AI. Previously, NLP was fragmented into many specific tasks (sentiment analysis, named entity recognition, etc.). With the rise of powerful transformers, many of these specialized tasks converged into the capabilities of large, general models.</p> <p>Now, agency might be enabling further consolidation. Tasks like information retrieval (textual or visual) and hallucination mitigation, previously handled by separate scaffolding or techniques like RAG, might increasingly become integrated into the model’s core agentic reasoning loop. As models become more general and capable agents, they can take on more of these sub-tasks themselves.</p> <p>In a way, it feels like the <a href="https://www.cs.utexas.edu/~eunsol/courses/data/bitter_lesson.pdf" rel="external nofollow noopener" target="_blank">Bitter Lesson</a> playing out once more. Instead of relying heavily on human-designed scaffolding and rule-based systems (like fixed retrieval strategies), perhaps it’s more effective to give the scaled-up model the agency and tools (like web search or image manipulation) and let <em>it</em> learn the best methods for gathering and utilizing information to solve the task at hand. Don’t inhibit the model with rigid external structures; let its own capabilities grow.</p> <p>It’s a simple shift – prompting the model to search when unsure, or allowing it to manipulate input images – but the underlying principle of empowering the model’s own agency to manage its information needs feels like a profound one.</p> </div> </article><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"ht0324/ht0324.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Hun Tae Kim. All Rights Reserved. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-7ZMBS6JQKV"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-7ZMBS6JQKV");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>