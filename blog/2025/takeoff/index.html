<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Are Fast AI Takeoffs Possible? | Hun Tae Kim</title> <meta name="author" content="Hun Tae Kim"> <meta name="description" content="Thinking through the implications of a detailed AI forecast and the possibility of rapid AI progress."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Source+Sans+3:ital,wght@0,300;0,400;0,500;0,600;0,700;1,400;1,600&amp;family=Source+Serif+4:ital,opsz,wght@0,8..60,400;0,8..60,500;0,8..60,600;0,8..60,700;1,8..60,400;1,8..60,600&amp;display=swap"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ht0324.github.io/blog/2025/takeoff/"> </head> <body class="fixed-top-nav " style="overflow-x: hidden; max-width: 100vw;"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title" href="/">Hun Tae Kim</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/Links/">Links</a> </li> <li class="nav-item "> <a class="nav-link" href="/CV/">CV</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" style="overflow-x: hidden;"> <div class="post"> <header class="post-header"> <h1 class="post-title">Are Fast AI Takeoffs Possible?</h1> <div class="post-meta-wrapper"> <span> <i class="fas fa-calendar fa-sm"></i> April 5, 2025 </span> </div> <div class="post-tag-wrapper"> <a href="/blog/tag/ai" class="tag-pill"> <i class="fas fa-hashtag fa-sm"></i> AI</a> <a href="/blog/category/thoughts" class="tag-pill"> <i class="fas fa-folder fa-sm"></i> Thoughts</a> </div> </header> <article class="post-content"> <div id="markdown-content"> <p>I recently spent a good chunk of time reading through the <a href="https://ai-2027.com/" rel="external nofollow noopener" target="_blank">“AI 2027” scenario forecast</a>. I’d seen it blowing up a bit online, partly because Scott Alexander helped write it. I wasn’t prepared for how dense and detailed it was. It took me a full day to really process it.</p> <p>I strongly encourage anyone interested in AI’s trajectory to read it. Even if you disagree with the specifics, it’s a valuable thought experiment. It forces you to get concrete about how different factors: capabilities like coding, hacking, research, compute scaling, agent deployment, geopolitics, might interact over the next few years.</p> <p>The post lays out a potential timeline, starting from our current reality of nascent AI agents and extrapolating based on trends and expert input. It simulates the compute race, particularly between hypothetical leading labs in the US (“OpenBrain”) and China (“DeepCent”), tracks the deployment of increasingly capable agents, and explores how these agents might accelerate AI R&amp;D itself. It culminates in two possible endings, “slowdown” and “race,” both thought-provoking.</p> <p>Here are some of my main reflections after digging into it.</p> <hr> <h3 id="the-ai-rd-threshold--its-plausibility">The AI R&amp;D Threshold &amp; Its Plausibility</h3> <p>My biggest non-trivial takeaway was realizing how the scenario pinpoints a critical phase: the point where AI reaches <em>human-level competence specifically in AI R&amp;D</em>. This might happen <em>before</em> we achieve what most people think of as full AGI across all domains.</p> <p>While just one possible future, the scenario makes a compelling case for why this specific threshold is so plausible and consequential. Tasks involved in AI research, especially coding and running experiments, are often <em>verifiable</em>. This makes them highly amenable to reinforcement learning and other techniques that can drive AI performance to superhuman levels relatively quickly. I hadn’t fully appreciated how massive the cumulative effects could be once this recursive loop truly kicks in.</p> <p>The plausibility is further underscored by real-world signals. One of the scenario’s authors is a former OpenAI researcher (<a href="https://x.com/DKokotajlo" rel="external nofollow noopener" target="_blank">Daniel Kokotajlo</a>), likely bringing informed perspectives. Furthermore, OpenAI itself is actively exploring research automation, collaborating with institutions like <a href="https://openai.com/index/openai-and-los-alamos-national-laboratory-work-together/" rel="external nofollow noopener" target="_blank">Los Alamos National Laboratory</a> and recently introducing benchmarks like <a href="https://openai.com/index/paperbench/" rel="external nofollow noopener" target="_blank">Paperbench</a> specifically to evaluate AI capabilities in AI research tasks. It seems highly likely that leading labs are seriously considering and pursuing this path. If they succeed, Dario Amodei’s concept of <a href="https://darioamodei.com/machines-of-loving-grace" rel="external nofollow noopener" target="_blank">“geniuses in a datacenter”</a> could become reality sooner than many expect.</p> <p>Once AI can effectively improve itself in this domain, the acceleration depicted in the scenario feels almost inevitable. The “country of geniuses in a datacenter” becomes an internal reality at leading labs <em>first</em>, potentially before the wider world fully grasps the shift. This internal acceleration, driven by superhuman coding and research agents, then fuels progress across the board.</p> <h3 id="the-geopolitical-tinderbox">The Geopolitical Tinderbox</h3> <p>The scenario also rightly highlights the intense geopolitical pressure cooker surrounding AI development. The AI arms race is a real risk factor that many AI safety experts are deeply concerned about. The potential for rapid, destabilizing capability gains could easily spiral out of control.</p> <p>I share the belief implicit in the scenario: the first nation to achieve truly general AI, especially one capable of recursive self-improvement via R&amp;D automation, would gain an almost insurmountable asymmetric advantage across <a href="https://www.youtube.com/live/esCSpbDPJik?t=1608s" rel="external nofollow noopener" target="_blank">military, scientific, and economic domains</a>. Given these stakes, it seems probable that major players like the US and China will continue pursuing AI dominance with an “all gas, no brakes” mentality, potentially prioritizing speed over caution.</p> <h3 id="the-commoditization-of-pure-coding">The Commoditization of Pure Coding</h3> <p>Reading through the scenario’s progression, where Agent-1, then Agent-2, and especially Agent-3 become superhuman coders, led me to a stark conclusion. Competing purely on implementation skills, just being a better coder, feels increasingly futile in the face of these potential developments. If the scenario is even directionally correct, raw coding ability might become a commodity handled vastly more efficiently by AI systems.</p> <hr> <p>The “AI 2027” scenario is speculative, of course. No one has a crystal ball. But its logical progression, built on current trends and plausible extrapolations, makes it powerful food for thought. It doesn’t present a determined future, but it maps out a <em>possible</em> one with startling clarity.</p> <p>When I first finished reading it in full, I was thunderstruck by the implications. While distilling specific takeaways felt challenging because the narrative is so interwoven, the <em>real</em> value for me was the shock, the “wow factor.” The main takeaway isn’t a single prediction, but the urgent need to <em>seriously consider</em> the possibility of a fast AI takeoff. The scenario also provides detailed metrics and reasoning behind its scaling assumptions (compute growth, algorithmic progress multipliers, etc.), offering a good starting point for anyone wanting to dig deeper into those quantitative aspects. Whether you agree with the outcome or not, grappling with the <em>possibility</em> it presents feels essential right now.</p> </div> </article><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"ht0324/ht0324.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Hun Tae Kim. All Rights Reserved. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-7ZMBS6JQKV"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-7ZMBS6JQKV");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>