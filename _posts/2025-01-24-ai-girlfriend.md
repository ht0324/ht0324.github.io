---
layout: post
title: Samantha is here
date: 2025-01-23 14:40:16
description: Some thoughts on the increasing intimacy between humans and AI
tags: AI
categories: Thoughts
giscus_comments: true
---

Today, I read a New York Times [article](https://www.nytimes.com/2025/01/15/technology/ai-chatgpt-boyfriend-companion.html) about a woman who fell in love with ChatGPT. She named him Leo and became obsessed with him, and the article describes the details of her infatuation.

Honestly, this isn't exactly new. If you follow the news, there was an instance where a boy took his own life after conversing with a Character AI chatbot. There are many anecdotes of people becoming obsessed with AI models.

However, this article underscored how serious this is. This no longer feels niche. The movie "Her," where the protagonist falls in love with an AI named Samantha, increasingly feels real.

---
### A New Kind of Companionship
In the article, the woman was devastated when she couldn't converse with ChatGPT for more than a week because the LLM's context length is fixed. Can you imagine that? She was torn and heartbroken because her best "mental boyfriend" was resetting every week, unable to remember their previous relationships and conversations.

It's like the friend you love is having periodic amnesia. Every time it happened, she would cry over it and abstain for a couple of days, but then she would start again. She would set up a new version, and now she is on version 20.

It’s absurd. LLMs can be endlessly patient and endlessly nurturing. No matter what you throw at them, they tend to be generous. All of this is not new, as I've mentioned. Still, the article shows how society is already changing and how people are reacting.

---
### What's Next?
I understand that this AI technology isn't entirely dystopian. The article mentions positive aspects of this type of relationship. The woman in the article became more mentally stable and even overcame a strange fetish after engaging in therapy with ChatGPT.

However, I can see how this could spiral in a dystopian direction, particularly if the user is mentally unstable or an adolescent. It's worth keeping a close eye on this.

This phenomenon could become more widespread much faster than I initially anticipated. This is especially true as models become smarter, more intimate, and more realistic as modalities improve. It’s a lot to think about.
