---
layout: post
title: Samantha is here
date: 2025-01-23 14:40:16
description: Some thoughts on the increasing intimacy between humans and AI
tags: AI
categories: thoughts
---

Today, I read a New York Times [article](https://www.nytimes.com/2025/01/15/technology/ai-chatgpt-boyfriend-companion.html) about a woman who fell in love with ChatGPT. She named him Leo and became obsessed with him, and the article delves into the details of her infatuation.
\
Honestly, this isn't exactly new. If you follow the news, there was an instance where a boy took his own life after conversing with a Character AI chatbot. There are many anecdotes of people becoming obsessed with AI models.

However, this article really highlighted the gravity of the situation. This could no longer be considered a niche occurrence. The movie "Her," where the protagonist falls in love with an AI named Samantha, is increasingly becoming our reality.

In the article, the woman was devastated when she couldn't converse with ChatGPT for more than a week because the LLM's context length is fixed. Can you imagine that? She was torn and heartbroken because her best "mental boyfriend" was resetting every week, unable to remember their previous relationships and conversations.

It's like the friend you love is having periodic amnesia. Every time it happened, she would cry over it and abstain for a couple of days, but then she would start again. She would set up a new version, and now she is on version 20.

It is very absurd. LLMs can be infinitely patient and infinitely nurturing. No matter what you throw at it, it will be infinitely generous to you. All of this is not new, as I've mentioned. However, the article really conveys a sense of gravity regarding how society is already changing and how individuals are reacting to it.

I understand that this AI technology isn't entirely dystopian. The article mentions positive aspects of this type of relationship. The woman in the article became more mentally stable and even overcame a strange fetish after engaging in therapy with ChatGPT.

However, I can see how this could spiral into a dystopian situation, particularly if the user is mentally unstable or an adolescent. It's crucial to keep a close eye on this issue.

This phenomenon could become more widespread much faster than I initially anticipated. This is especially true as models become smarter, more intimate, and more realistic as their modalities are enhanced. It really gives a lot of food for thought.